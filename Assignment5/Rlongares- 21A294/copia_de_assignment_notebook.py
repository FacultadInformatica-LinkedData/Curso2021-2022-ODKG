# -*- coding: utf-8 -*-
"""Copia de Assignment-Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10Hh7K4QWNQWyWyoot5CVNOMYJp4_3gT5
"""
"""

!pip install kgtk==1.0.1

!echo "deb http://downloads.skewed.de/apt bionic main" >> /etc/apt/sources.list
!apt-key adv --keyserver keys.openpgp.org --recv-key 612DEFB798507F25
!apt-get update
!apt-get install python3-graph-tool python3-cairo python3-matplotlib
!apt-get install libcairo2-dev
"""
"""## Preamble: set up the environment and files used in the assignment (remember to restart runtime)"""

import io
import os
import subprocess
import sys

import math
import numpy as np
import pandas as pd
from graph_tool.all import *
from IPython.display import display, HTML
from rdflib.plugins.sparql import prepareQuery
import requests
import json
from pandas import json_normalize

from kgtk.configure_kgtk_notebooks import ConfigureKGTK
from kgtk.functions import kgtk, kypher

# Parameters

# Folder on local machine where to create the output and temporary folders
input_path = None
output_path = "/tmp/projects"
project_name = "assignment"

"""The following command will download all the files you  need for the assignment:"""

url = 'https://query.wikidata.org/sparql'
files = [
    "all",
    "label",
    "alias",
    "description",
    "external_id",
    "monolingualtext",
    "quantity",
    "string",
    "time",
    "item",
    "wikibase_property",
    "qualifiers",
    "datatypes",
    "p279",
    "p279star",
    "p31",
    "in_degree",
    "out_degree",
    "pagerank_directed",
    "pagerank_undirected"
]
ck = ConfigureKGTK(files)
ck.configure_kgtk(input_graph_path=input_path,
                  output_path=output_path,
                  project_name=project_name)

"""The KGTK setup command defines environment variables for all the files so that you can reuse the Jupyter notebook when you install it on your local machine."""

ck.print_env_variables()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# ck.load_files_into_cache()

"""# About this assignment.
This assignment is based on https://github.com/usc-isi-i2/kgtk-notebooks/tree/main/tutorial. If you have any questions or doubts, it is encouraged to look how the tutorial performs the different operations.

Additional information can be found in https://kgtk.readthedocs.io/

## Simple graph statistics

Let's calculate first some statistics about the KG. Count the number of instances:
"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# kgtk("""
#     query -i all
#         --match '(instance)-[:P31]->(class)'
#         --return 'count(distinct instance) as count_instances'
# """)

"""Now, count the number of distinct properties: 

"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# kgtk("""
#     query -i all
#         --match '(instance)-[l {label: property}]->(class)'
#         --return 'count(distinct property) as count_property'
# """)

"""Now, let's count the frequency of those properties. That is, how many instances we can find with each property"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# kgtk("""
#     query -i all
#         --match '(instance)-[:P31]->(class)'
#         --match '(instance)-[l {label: property}]->(class)'
#         --return 'l.label,count(distinct instance) as frequencies'
#         
# """)
#

"""## Simple queries
Some of these queries are simple and will run in the Wikidata endpoint. 
Try both of them using SPARQL and Kypher
"""

# Which actors has Schwarzenegger worked with throughout his career? (Print also the movie)

# (in SPARQL)
print("\n\nWhich actors has Schwarzenegger worked with throughout his career?")
print("\n\nWith SPARQL")



q1 = '''
    SELECT ?actor ?movie ?actorLabel ?movieLabel WHERE {
   ?movie wdt:P161 wd:Q2685.
   ?movie wdt:P161 ?actor.
   FILTER (?actor != wd:Q2685)
   SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
 }'''



r = requests.get(url, params = {'format': 'json', 'query': q1})
data = r.json()
print(data)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
df = json_normalize(data['results']['bindings'])
print(df.head()) 


# In Kypher:
print("\n\nWith Kypher")
print(kgtk("""
    query -i all
    --match '(:Q2685)<-[:P161]-(movie)-[:P161]->(actor)'
    --where 'actor != "Q2685"'
     --return 'actor as actor, movie as movie'
    / add-labels
"""))

# How many awards does Schwarzenegger have?
print("\n\nHow many awards does Schwarzenegger have?")
print("\n\nWith SPARQL")
# SPARQL:
q2 = '''
    SELECT (
    COUNT(distinct  ?award) AS ?count_awards) 
    WHERE {    
    wd:Q2685 wdt:P166 ?award
    }'''



r2 = requests.get(url, params = {'format': 'json', 'query': q2})
data = r2.json()
print(data)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
df = json_normalize(data['results']['bindings'])
print(df.head()) 
print("\n\nWith Kypher")
# Kypher:
print(kgtk("""
    query -i all \
     --match '(:Q2685)-[:P166]->(award)' \
     --return 'count(distinct award) as awards'
"""))

# Retrieve at least two members of Schwarzenegger's political party. Make sure only persons are returned
print("\n\nRetrieve at least two members of Schwarzenegger's political party. Make sure only people are returned")
print("\n\nWith SPARQL")
# SPARQL:
q3 = '''
   SELECT ?other ?party ?otherLabel ?partyLabel WHERE {
   wd:Q2685 wdt:P102 ?party.
   ?other wdt:P102 ?party.
   ?other wdt:P31 wd:Q5.
   SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }
   FILTER (?other != wd:Q2685)
    }'''

r3 = requests.get(url, params = {'format': 'json', 'query': q3})
data = r3.json()
#print(data)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
df = json_normalize(data['results']['bindings'])
print(df.head()) 
print("\n\nWith Kypher")
# Kypher:
print(kgtk("""
    query -i all \
     --match '(:Q2685)-[:P102]->(party)<-[:P102]-(member)-[:P31]->(:Q5)'
    --where 'member != "Q2685"'
     --return 'member, party'
     --limit 10 
    / add-labels
"""))

# What are the properties that describe an artist?

# In theory this one is heavy on Wikidata
print("\n\nWhat are the properties that describe an artist?")
print("\n\nWith SPARQL")
# SPARQL:
q4 = '''
   SELECT DISTINCT ?property  
  WHERE {
  ?artista wdt:P106/rdfs:subClassOf* wd:Q483501.
  ?artista ?property ?o.        
  SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en".}
  }LIMIT 133'''

r4 = requests.get(url, params = {'format': 'json', 'query': q4})
data = r4.json()
print(data)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
df = json_normalize(data['results']['bindings'])
print(df.head()) 
print("\n\nWith Kypher")
# Kypher:
print(kgtk("""
    query -i all
      --match '()<-[l {label: property}]-(element)-[:P106]->(class)-[:P279star]->(:Q483501)'
      --return 'distinct property'
     --limit 10 
    / add-labels
"""))

# And a film director?
print("\n\nAnd a film director?")
print("\n\nWith SPARQL")
# SPARQL:
q5 = '''
   SELECT DISTINCT ?property  
  WHERE {
  ?artista wdt:P106/rdfs:subClassOf* wd:Q2526255.
  ?artista ?property ?o.        
  SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en".}
  }LIMIT 133'''

r5 = requests.get(url, params = {'format': 'json', 'query': q5})
data = r5.json()
print(data)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
df = json_normalize(data['results']['bindings'])
print(df.head()) 
print("\n\nWith Kypher")
# Kypher:
print(kgtk("""
    query -i all
      --match '()<-[l {label: property}]-(element)-[:P106]->(class)-[:P279star]->(:Q2526255)'
      --return 'distinct property'
     --limit 10 
    / add-labels
"""))

# Embeddings. Run the noebook https://colab.research.google.com/drive/1A55l10voA4jnjoju3fojJWY3buLfaR4i?usp=sharing. 
# Which are the top 10 similar entities to Schwarzenegger? (list below) 
print("\n\nWhich are the top 10 similar entities to Schwarzenegger? (list below) ")
print('''
    1.- Arnold Schwarzenegger
    2.- Hugh Dancy
    3.- Carl Laemmle
    4.- Wallace Shawn'
    5.- 'Ted Turner'
    6.- John Travolta
    7.- Jeremy Brett
    8.- Elyas M\'Barek'
    9.- Fred Rogers
    10.- Harvey Fierstein''')

"""## Network analysis
Print all the paths between Schwarzenegger and Trump

## Note that **you have to create a file `paths.tsv` with the node pairs you want to find the paths for. Upload it in the "content" folder**

"""

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# cat <<EOF >$TEMP/path-query.tsv
# node1	node2	label
# Q2685	Q22686	path

kgtk("""
    add-labels -i $TEMP/path-query.tsv
""")

# Calculate all the paths between Trump and Schwarzenegger (max hops: 3)
# TO DO 
print("\n\nCalculate all the paths between Trump and Schwarzenegger (max hops: 3)")   
print(kgtk("""
    paths -i all
          --path-file $TEMP/path-query.tsv
          --statistics-only True
          --max_hops 3
"""))

# Retrieve all the family of Schwarzenegger (child/father/mother/sibling/spouse relationships)
# TO DO  
print("\n\nRetrieve all the family of Schwarzenegger (child/father/mother/sibling/spouse relationships)")  
print(kgtk("""
     reachable-nodes -i $item
        --root Q2685
        --props P40 P3373 P26 P22 P25
        --label Pextended_family
    / add-labels
"""))

# What are the 10 most relevant actors (pagerank) in the graph? (Use graph-statistics command to calculate page rank, and then filter only actors)
# TO DO  
print("\n\nWhat are the 10 most relevant actors (pagerank) in the graph? (Use graph-statistics command to calculate page rank, and then filter only actors)")  

print(kgtk("""
    graph-statistics -i all -o /tmp/projects/assignment/metadata.pagerank.undirected.tsv.gz
    --compute-pagerank True
    --compute-hits False
    --page-rank-property P_pagerank
    --output-pagerank True
    --output-statistics-only
    --output-hits False
    --undirected True
    --log-file /tmp/projects/assignment/metadata.pagerank.undirected.summary.txt
"""))

# TO DO: Hint: do the query after calculating the pagerank. See https://github.com/usc-isi-i2/kgtk-notebooks/blob/main/tutorial/06-kg-network-analysis.ipynb for inspiration

print("\n\nHint: do the query after calculating the pagerank. See https://github.com/usc-isi-i2/kgtk-notebooks/blob/main/tutorial/06-kg-network-analysis.ipynb for inspiration")  
print(kgtk("""
    query -i item -i $OUT/metadata.pagerank.undirected.tsv.gz
        --match '
            item: (actor)<-[:P161]-(film)-[:P31]->(:Q11424),
            pagerank: (actor)-[:Pdirected_pagerank]->(pagerank)'
        --return 'actor as Ac, pagerank as Importance'
        --order-by 'cast(pagerank, float) desc'
        --limit 10
    / add-labels
"""))